{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basics\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "from collections import namedtuple\n",
    "\n",
    "#import environment\n",
    "import sys\n",
    "sys.path.append(r'../virl')\n",
    "import virl\n",
    "\n",
    "from policy_search_ds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.25 0.25 0.25]\n",
      "Step 0 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 1 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 2 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 3 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 4 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 5 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 6 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 7 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 8 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 9 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 10 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 11 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 12 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 13 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 14 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 15 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 16 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 17 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 18 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 19 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 20 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 21 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 22 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 23 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 24 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 25 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 26 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 27 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 28 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 29 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 30 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 31 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 32 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 33 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 34 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 35 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 36 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 37 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 38 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 39 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 40 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 41 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 42 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 43 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 44 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 45 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 46 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 47 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 48 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 49 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 50 @ Episode 1/5 (0.0)[0.25 0.25 0.25 0.25]\n",
      "Step 51 @ Episode 1/5 (0.0)update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "update\n",
      "[nan nan nan nan]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f35d77b5407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpolicy_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetworkPolicyEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreinforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_discrete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/OneDrive - University of Glasgow/AI H/AiCourseWork/PolicySearchTab_Jiahui/policy_search_ds.py\u001b[0m in \u001b[0;36mreinforce\u001b[0;34m(env, estimator_policy, num_episodes, discount_factor, use_discrete)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "env = virl.Epidemic(problem_id=0, stochastic=False, noisy=False)\n",
    "\n",
    "# Instantiate a PolicyEstimator (i.e. the function-based approximation)\n",
    "alpha      = 0.001  \n",
    "n_states = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "nn_config  = [12] # number of neurons in the hidden layers, should be [] as default\n",
    "\n",
    "policy_estimator = NeuralNetworkPolicyEstimator(alpha, n_actions, n_states, nn_config)\n",
    "\n",
    "stats = reinforce(env, policy_estimator, 5, discount_factor=0.99, use_discrete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
